{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HANDL \n",
    "\n",
    "The goal of HANDL is to support the transfer of biological knowledge across species.  It does so by constructing explicit measures of functional similarity between proteins in different species.   HANDL (Homology Assessment across Networks using Diffusion and Landmarks) creates a functional embedding in which proteins from different species are embedded in the same vector space. In the paper [1] it is shown that inner products in this space _(HANDL homology scores)_, as well as the vectors themselves _(HANDL embeddings)_, capture functional similarity across species and are useful for a variety of functional tasks.\n",
    "\n",
    "[1] [A Multi-Species Functional Embedding Integrating Sequence and\n",
    "Network Structure](https://www.biorxiv.org/content/early/2017/12/04/229211), Mark D.M. Leiserson, Jason Fan, Anthony Cannistra, Inbar Fried, Tim Lim, Thomas Schaffner, Mark Crovella, and Benjamin Hescott, _Proceedings of RECOMB 2018,_ Paris, France.\n",
    "\n",
    "## Background\n",
    "\n",
    "An overview of HANDL is shown in the figure below.  Starting with a source and a target network, HANDL computes diffusion kernels for each network. The diffusion kernels are factored, resulting in a representation in which each node becomes a vector, and inner products correlate with functional similarities. HANDL then solves a linear system to create a single embedding of both vector sets, allowing for functional comparisons between proteins across the two networks.\n",
    "\n",
    "![HANDL Overview](figures/handl-methods.jpg)\n",
    "\n",
    "As shown in the figure, HANDL works with the notion of a _source_ species and one or more _target_ species.  The proteins of the target species are embedded into a space defined by the source species.\n",
    "\n",
    "## This workbook\n",
    "\n",
    "This workbook illustrates how to compute HANDL embeddings and HANDL homology scores as described in [1].  As a demonsration, we compute functional similarity between proteins in _S. cerevisiae_ (Sc) and _S. pombe_ (Sp)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration \n",
    "\n",
    "This workbook assumes that the [HANDL demo repository](https://github.com/theJasonFan/HANDL) has been downloaded, and that data has been retrieved and prepared as described in the __Data__ section of the [README](https://github.com/theJasonFan/HANDL/blob/master/README.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import scipy\n",
    "import sklearn\n",
    "import sklearn.neighbors\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the functions we will use are in associated libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import util\n",
    "from network import regularized_laplacian, rkhs_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration parameters:\n",
    "* `source`: Source species\n",
    "* `target`: Target species\n",
    "* `lam`: Value of $\\lambda$ used in computing the Regularized Laplacian\n",
    "* `data_dir`: Directory holding all data\n",
    "* `n_landmarks`: Number of landmarks to use in constructing the embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source = 'sc'\n",
    "target = 'sp'\n",
    "lam = 0.05\n",
    "data_dir = '../data'\n",
    "n_landmarks = 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HANDL embedding\n",
    "\n",
    "The first stage of the HANDL embedding involves the following steps:\n",
    "\n",
    "1. Construct PPI networks for source and target species\n",
    "2. Reduce each network to its 2-core (see paper for explanation).\n",
    "3. Compute the Laplacian $L$ and Regularized Laplacian $D = (I + \\lambda L)^{-1}$ for each species.\n",
    "4. Factor the Regularized Laplacian to get HANDL embedding vectors $D = CC^T$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-12-23 14:30:57,180 util.py         INFO      : PPI info - # Nodes: 5893, # Edges: 492146\n",
      "2017-12-23 14:30:57,181 util.py         INFO      : Computing 2 core\n",
      "2017-12-23 14:31:00,275 util.py         INFO      : 2 core info - # Nodes: 5865, # Edges: 492118\n",
      "2017-12-23 14:31:00,276 util.py         INFO      : 2 core removed 28 nodes and 28 edges\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'sc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-ad60a5f3cdb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimple_two_core\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mspecies\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaplacian_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mspecies\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodelist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mspecies\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtodense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mspecies\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregularized_laplacian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mC\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mspecies\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrkhs_factor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mspecies\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/networkx/classes/graph.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0;34m{\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m         \"\"\"\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'sc'"
     ]
    }
   ],
   "source": [
    "nodes = {}\n",
    "D = {}\n",
    "C = {}\n",
    "for species in [source, target]:\n",
    "    ppi_edgelist = '{}/ppi/biogrid/{}/biogrid-{}-std-network.txt'.format(\n",
    "        data_dir, species, species)\n",
    "    G = nx.read_edgelist(ppi_edgelist, encoding='ascii')\n",
    "    G = util.simple_two_core(G)\n",
    "    nodes[species] = sorted(G.nodes())\n",
    "    L = np.array(nx.laplacian_matrix(G[species], nodelist=nodes[species]).todense())\n",
    "    D[species] = regularized_laplacian(L, lam)\n",
    "    C[species] = rkhs_factor(D[species])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second stage of the HANDL embedding uses known homologs between the two species.  First we read in the set of all known homologs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume the order in homolog file is source node, target node\n",
    "homolog_list = '{}/homologs/sc-sp/sc-sp-homologs.txt'.format(\n",
    "    data_dir)\n",
    "source_homs = []\n",
    "target_homs = []\n",
    "with open(homolog_list, 'r') as hom_f:\n",
    "    for line in hom_f:\n",
    "        source_hom, target_hom = line.split()\n",
    "        if (source_hom in nodes[source]) and (target_hom in nodes[target]):\n",
    "            source_homs.append(source_hom)\n",
    "            target_homs.append(target_hom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source_homolog_indices = [nodes[source].index(node) for node in source_homs]\n",
    "target_homolog_indices = [nodes[target].index(node) for node in target_homs]\n",
    "source_landmarks = source_homs[:n_landmarks]\n",
    "target_landmarks = target_homs[:n_landmarks]\n",
    "\n",
    "source_landmark_indices = source_homolog_indices[:n_landmarks]\n",
    "source_non_landmark_indices = source_homolog_indices[n_landmarks:]\n",
    "target_landmark_indices = target_homolog_indices[:n_landmarks]\n",
    "target_non_landmark_indices = target_homolog_indices[n_landmarks:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding of target species\n",
    "\n",
    "select corresponding rows in each vector set and regress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_handl_C = np.linalg.pinv(C[source][source_landmark_indices,:]).dot(\n",
    "    D[target][target_landmark_indices,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HANDL homology scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_cross_species = C[source].dot(target_handl_C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot homolog density (Figure 2 from paper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters for plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_lim = 0.8\n",
    "font_size = 12\n",
    "line_width = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this plot we want to work with dissimilarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Dissim = 1./D_cross_species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Dissim = Dissim / np.mean(Dissim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't want to use known landmark-homologs so we remove those entries from the HANDL score matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source_valid = [r for r in range(Dissim.shape[0])\n",
    "                        if r not in source_landmark_indices]\n",
    "target_valid = [r for r in range(Dissim.shape[1])\n",
    "                        if r not in target_landmark_indices]\n",
    "Dissim = Dissim[source_valid][:,target_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# update the names of rows and columns\n",
    "source_nodes = [n for i, n in enumerate(nodes[source]) if i in source_valid]\n",
    "target_nodes = [n for i, n in enumerate(nodes[target]) if i in target_valid]\n",
    "\n",
    "# update these indices as well\n",
    "source_non_landmark_indices = [source_nodes.index(node) for node in source_homs\n",
    "                                       if node not in source_landmarks]\n",
    "target_non_landmark_indices = [target_nodes.index(node) for node in target_homs\n",
    "                                       if node not in target_landmarks]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get HANDL scores for Non-landmark homologs\n",
    "NLH = Dissim [source_non_landmark_indices,target_non_landmark_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create kernel density estimator\n",
    "kde = sklearn.neighbors.KernelDensity(kernel='gaussian',\n",
    "                                              bandwidth = plot_lim / 20.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# need to add another dimension as required by sklearn\n",
    "# arrays passed to kde must be 2-dimensional\n",
    "X_plot = np.reshape(np.linspace(0, plot_lim, 500), (-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Density of non-landmark homolog pairs\n",
    "kde.fit(np.reshape(np.ravel(NLH), (-1, 1)))\n",
    "NLHdens = kde.score_samples(X_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Density of all pairs\n",
    "Dsamp = np.random.choice(np.ravel(Dissim),100000)\n",
    "kde.fit(np.reshape(Dsamp, (-1, 1)))\n",
    "Ddens = kde.score_samples(X_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X_plot[:,0], np.exp(NLHdens), lw = line_width,\n",
    "                 label = 'Homolog Pairs')\n",
    "plt.plot(X_plot[:,0], np.exp(Ddens), '-.',\n",
    "                 lw = line_width, ls = (0,(5,2)), label = 'All Pairs')\n",
    "plt.ylabel('Density', size = font_size)\n",
    "plt.xlabel('HANDL dissimilarity', size = font_size)\n",
    "plt.legend(loc='best', fontsize = font_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
